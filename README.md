# Enhancing Depression Detection via Question-wise Modality Fusion

## Abstract

Depression is a highly prevalent and disabling condition that incurs substantial personal and societal costs. Current depression diagnosis involves determining the depression severity of a person through self-reported questionnaires or interviews conducted by clinicians. This often leads to delayed treatment and involves substantial human resources. Thus, several works have tried to automate the process using multimodal data. However, they overlooked the dynamic contribution of each modality for each question in the questionnaire, thus leading to sub-optimal fusion. In this work, we propose a novel Question-wise Modality Fusion (\textit{QuestMF}) framework to tackle this issue. Our framework outperforms current state-of-the-art models on the E-DAIC dataset. In addition, we provide an analysis to understand each modality's contribution to each question's scoring. Our framework also offers symptom-specific insights, leading to greater interpretability and specificity in depression detection, which can facilitate more personalised interventions.

## Dataset

For this work we use the E-DAIC dataset used in the AVEC-2019 challenge. The dataset can be found here: https://dcapswoz.ict.usc.edu/

## Contact
For any questions contact: [Aishik Mandal](aishik.mandal@tu-darmstadt.de) <br>
[UKP Lab](https://www.informatik.tu-darmstadt.de/ukp/ukp_home/index.en.jsp) | [TU Darmstadt](https://www.tu-darmstadt.de/) 

## Disclaimer

This repository contains experimental software and is published for the sole purpose of giving additional background details on the respective publication.
